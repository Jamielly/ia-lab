{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39756541",
   "metadata": {},
   "source": [
    "Chatbot com IA generativa com Gemini -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bacf223",
   "metadata": {},
   "source": [
    "Gera respostas com base apenas no modelo da IA (Gemini, GPT, Claude, etc). Ele usa o conhecimento pré-treinado da IA, nesse caso, eu utilizei a API do Gemini para alimentar o meu chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e16578",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ce575",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7e8f5",
   "metadata": {},
   "source": [
    "É importante nunca deixar a sua chave API pública, é uma questão de segurança!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeed9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "# Lê a chave do ambiente ou direto do código (troque conforme método escolhido)\n",
    "# GOOGLE_API_KEY = \"SUA_CHAVE_AQUI\"  # <-- método simples\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')  # <-- método seguro\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21652d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Aconselho verificar os modelos para evitar erros\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37384f31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26143d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Teste rápido\n",
    "response = model.generate_content(\"Quem criou o Gemini?\")\n",
    "print(\"Resposta:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ede0ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Iniciação do chat interativo\n",
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8c078",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Laço de repetição para verificação garantir uma boa \"interface\" e um funcionamento bacana\n",
    "while True:\n",
    "    prompt = input(\"\\nVocê: \")\n",
    "    if prompt.lower() in [\"fim\", \"sair\", \"exit\"]:\n",
    "        print(\"Encerrando chat...\")\n",
    "        break\n",
    "\n",
    "    response = chat.send_message(prompt)\n",
    "    print(\"Gemini:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346d278",
   "metadata": {},
   "source": [
    "Alguns testes -----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a8158",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#chat = model.start_chat(history=[])\n",
    "#prompt = input(\"Esperando o prompt: \")\n",
    "#while prompt != \"fim\":\n",
    "#response = chat.send_message(prompt)\n",
    "#print(response.text)\n",
    "#prompt = input(\"do que é feita o planeta terra?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46da9b",
   "metadata": {},
   "source": [
    "Chatbot com RAG (Retrieval-Augmented Generation) -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa7de6",
   "metadata": {},
   "source": [
    "Antes de responder, o bot faz uma busca em uma base de dados, documentos, PDFs, sites, etc — e usa esse conteúdo real como contexto para gerar a resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135522c",
   "metadata": {},
   "source": [
    "Um repositório de conhecimento\n",
    "(pode ser uma pasta com PDFs, um banco de dados, ou até um site).\n",
    "\n",
    "Um módulo de busca semântica ou embedding, ex:\n",
    "\n",
    "faiss, chromadb, langchain, llama_index\n",
    "pra fazer busca vetorial (comparar significado de textos).\n",
    "\n",
    "Um pipeline tipo esse:\n",
    "pergunta → gerar embedding → buscar trechos relevantes → juntar contexto → enviar pro modelo (Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82fb14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from google.generativeai import GenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091f9c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Embeddings com Gemini\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463be0b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Indexa documentos (exemplo PDF convertido em texto)\n",
    "vectorstore = FAISS.from_texts([\"texto do doc 1\", \"texto do doc 2\"], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3412f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Cria o retriever (busca semântica)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed92e0b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Cria o modelo generativo\n",
    "model = GenerativeModel(\"gemini-2.5-pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203dd39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Cria o pipeline RAG\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680e6e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Faz uma pergunta contextualizada\n",
    "resposta = qa.run(\"O que esse documento diz sobre privacidade de dados?\")\n",
    "print(resposta)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
